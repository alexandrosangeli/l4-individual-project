{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from helpers.helper import get_cath\n",
    "\n",
    "from Bio import pairwise2\n",
    "from Bio.pairwise2 import format_alignment\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "\n",
    "import requests\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "import shutil\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "cath = get_cath()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the reverse mapping\n",
    "with open('../data/sword2/SWORD2/misc/reverse_mappings_compact.json') as json_file:\n",
    "    pdb_uniprot_mappings_reverse = json.load(json_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SWORD parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sword2(code, version, verb=False):\n",
    "    file = f\"../data/sword2/SWORD2/results/{version}/{code}/{code}_A/sword.txt\"\n",
    "    with open(file, \"r\") as f:\n",
    "        data = {}\n",
    "        lines = f.readlines()\n",
    "        option = 0\n",
    "        for i, line in enumerate(lines):\n",
    "            lines[i] = \"\".join([c for c in line if c not in [\"\\n\",'']])\n",
    "            if line != \"\\n\":\n",
    "                if not line.startswith((\"PDB:\", \"#D\", \"A\")):\n",
    "                    res = lines[i].split(\"|\")\n",
    "                    boundaries = res[2]\n",
    "                    domains = boundaries.strip().split(\" \")\n",
    "                    data[f\"option{option}\"] = {}\n",
    "                    for j in range(len(domains)):\n",
    "                        data[f\"option{option}\"][str(j+1)] = domains[j]\n",
    "                    option += 1\n",
    "    verb and pprint(data)\n",
    "    return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dbd_score(y_pred, y_true, margin=20):\n",
    "    scores = []\n",
    "    for i in range(len(y_pred)):\n",
    "        window = y_true[max(0, i-margin):min(len(y_true), i+margin+1)]\n",
    "        indices_window = list(range(max(0, i-margin), min(len(y_true), i+margin+1)))\n",
    "        if y_pred[i] == 1.0:\n",
    "            if 1.0 in window:\n",
    "                # if it's within the window, calculate the score\n",
    "                pos = np.where(window == 1.0)[0][0]\n",
    "                j = indices_window[pos]\n",
    "                diff = abs(i - j)\n",
    "                k = 0 if diff == 0 else 1\n",
    "                score = ((margin - diff) + k) / margin\n",
    "            else:\n",
    "                # false positive\n",
    "                score = 0\n",
    "            scores.append(score)\n",
    "\n",
    "    number_of_true_boundaries = np.sum(y_true)\n",
    "    number_of_pred_boundaries = np.sum(y_pred)\n",
    "    max_len = max(number_of_true_boundaries,number_of_pred_boundaries)\n",
    "    if max_len == 0:\n",
    "        return 1.0\n",
    "\n",
    "    return np.sum(scores) / max_len\n",
    "\n",
    "\n",
    "def observations(y_pred, y_true, margin):\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "\n",
    "    dbd = dbd_score(y_pred, y_true, margin)\n",
    "    for i in range(len(y_pred)):\n",
    "        window = y_true[max(0, i-margin):min(len(y_true), i+margin+1)]\n",
    "        indices_window = list(range(max(0, i-margin), min(len(y_true), i+margin+1)))\n",
    "        if y_pred[i] == 1.0:\n",
    "            if 1.0 in window:\n",
    "                pos = np.where(window == 1.0)[0][0]\n",
    "                j = indices_window[pos]\n",
    "                y_true[j] = 0.0\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "\n",
    "\n",
    "        elif y_pred[i] == 0.0:\n",
    "            if  y_true[i] == 1.0:\n",
    "                fn += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "\n",
    "    return (tp, tn, fp, fn)\n",
    "\n",
    "\n",
    "def metrics(y_pred, y_true, margin=20):\n",
    "    tp, tn, fp, fn = observations(y_pred, y_true, margin)\n",
    "\n",
    "    accuracy = (tn + tp) / (tn + tp + fn + fp) if (tn + tp + fn + fp) else 0\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) else 0\n",
    "\n",
    "    recall = tp / (tp + fn) if (tp + fn) else 0\n",
    "\n",
    "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "\n",
    "    mcc_num = (tp * tn) - (fp * fn)\n",
    "    mcc_den = np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "    mcc = mcc_num / mcc_den if mcc_den else 0\n",
    "\n",
    "    dbd = dbd_score(y_pred, y_true, margin)\n",
    "\n",
    "    return (accuracy, precision, recall, f1, mcc, dbd)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundaries2(len_seq, domain, discontinuity_delimiter):\n",
    "\t\"\"\"\n",
    "\t\tDefines a boundary as the beginning of a domain ONLY in multi-domain proteins\n",
    "\t\"\"\"\n",
    "\tfirst_start = np.inf\n",
    "\tbounds = np.zeros((len_seq), dtype=np.int8)\n",
    "\tfor k, v in domain.items():\n",
    "\t\tboundary_positions = v.split(discontinuity_delimiter)\n",
    "\t\tfor b in boundary_positions:\n",
    "\t\t\tstart, end = [int(i) for i in b.split('-')]\n",
    "\t\t\tif start < first_start:\n",
    "\t\t\t\tfirst_start = start\n",
    "\t\t\tbounds[start-1] = 1\n",
    "\tbounds[first_start-1] = 0            \n",
    "\treturn np.array(bounds, dtype=np.bool_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_af_chain(code):\n",
    "\tfile_path = f\"../data/sword2/SWORD2/misc/af_pdbs/AF-{code}-F1-model_v3.pdb\"\n",
    "\tchains = {record.id: record.seq for record in SeqIO.parse(file_path, 'pdb-seqres')}\n",
    "\ta_chain_uniprot_seq = chains['XXXX:A']\n",
    "\treturn a_chain_uniprot_seq\n",
    "\n",
    "\n",
    "def get_pdb_chain(code):\n",
    "\tpdb_file_path = f\"../data/pdb/bulk/balanced/backup/data/{code}.pdb\"\n",
    "\tpdb_chains = {record.id: record.seq for record in SeqIO.parse(pdb_file_path, 'pdb-seqres')}\n",
    "\n",
    "\tfor key in pdb_chains.keys():\n",
    "\t\tif key[-1] == 'A':\n",
    "\t\t\ta_chain_pdb_seq = pdb_chains[key]\n",
    "\t\t\treturn a_chain_pdb_seq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50/443]\n",
      "[100/443]\n",
      "[150/443]\n",
      "[200/443]\n",
      "[250/443]\n",
      "File not found Q9YDZ4 2hls\n",
      "[300/443]\n",
      "[350/443]\n",
      "File not found P38505 1jfj\n",
      "[400/443]\n",
      "[443/443]\n"
     ]
    }
   ],
   "source": [
    "path = '../data/sword2/SWORD2/results/af'\n",
    "\n",
    "uniprots = os.listdir(path)\n",
    "# print(uniprots)\n",
    "# print()\n",
    "\n",
    "pdb_mcc = []\n",
    "af_mcc = []\n",
    "\n",
    "for i, id in enumerate(uniprots):\n",
    "\n",
    "    pdb = pdb_uniprot_mappings_reverse[id]\n",
    "    a_chain_uniprot_seq = get_af_chain(id)\n",
    "    a_chain_pdb_seq = get_pdb_chain(pdb)\n",
    "    chain_len = None\n",
    "    if len(a_chain_pdb_seq) != len(a_chain_uniprot_seq):\n",
    "        raise ValueError(\"Different sequence lengths is not expected\")\n",
    "    else:\n",
    "        chain_len = len(a_chain_pdb_seq)\n",
    "    \n",
    "    baseline = cath[pdb]['A']\n",
    "    af_sword_results = get_sword2(id, 'af', verb=False)\n",
    "    try:\n",
    "        pdb_sword_results = get_sword2(pdb, 'pdb', verb=False)\n",
    "    except FileNotFoundError:\n",
    "        print(\"File not found\", id, pdb)\n",
    "        continue\n",
    "\n",
    "\n",
    "    margin = 20\n",
    "    baseline_boundaries = boundaries2(len(a_chain_pdb_seq), baseline, ',').astype(int)\n",
    "    pdb_mccs = []\n",
    "    af_mccs = []\n",
    "    pdb_dbds = []\n",
    "    af_dbds = []\n",
    "\n",
    "    for option, domain in pdb_sword_results.items():\n",
    "        pdb_sword_boundaries = boundaries2(chain_len, domain, ';').astype(int)\n",
    "        pdb_sword_metrics = metrics(pdb_sword_boundaries, baseline_boundaries, margin)\n",
    "        pdb_sword_mcc = pdb_sword_metrics[-2]\n",
    "        pdb_sword_dbd = pdb_sword_metrics[-1]\n",
    "        pdb_mccs.append(pdb_sword_mcc)\n",
    "        pdb_dbds.append(pdb_sword_dbd)\n",
    "\n",
    "    for option, domain in af_sword_results.items():\n",
    "        af_sword_boundaries = boundaries2(chain_len, domain, ';').astype(int)\n",
    "        af_sword_metrics = metrics(af_sword_boundaries, baseline_boundaries, margin)\n",
    "        af_sword_mcc = af_sword_metrics[-2]\n",
    "        af_sword_dbd = af_sword_metrics[-1]\n",
    "        af_mccs.append(af_sword_mcc)\n",
    "        af_dbds.append(af_sword_dbd)\n",
    "\n",
    "    best_pdb_i = np.argmax(pdb_mccs)\n",
    "    best_af_i = np.argmax(af_mccs)\n",
    "\n",
    "    pdb_mcc.append(pdb_mccs[best_pdb_i])\n",
    "    af_mcc.append(af_mccs[best_af_i])\n",
    "\n",
    "    if (i + 1) % 50 == 0:\n",
    "        print(f\"[{i + 1}/{len(uniprots)}]\")\n",
    "print(f\"[{i + 1}/{len(uniprots)}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean PDB MCC: 0.6210332441611623\n",
      "Mean AF MCC: 0.13217732495763904\n",
      "27.3760386666944 7.451803918104624e-120\n"
     ]
    }
   ],
   "source": [
    "t_stat, p_val = ttest_ind(pdb_mcc, af_mcc)\n",
    "\n",
    "print(\"Mean PDB MCC:\", np.mean(pdb_mcc))\n",
    "print(\"Mean AF MCC:\", np.mean(af_mcc))\n",
    "\n",
    "print(t_stat, float(p_val))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean PDB MCC: 0.7312201785001735\n",
    "\n",
    "Mean AF MCC: 0.04587217486107879\n",
    "\n",
    "56.20185031552613 2.0480532531702836e-293"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b6993604730f8cf29f5900b73e8b88206f8a6983047fdc957f382b3e5d49baa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
