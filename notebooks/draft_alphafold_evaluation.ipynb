{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from helpers.helper import get_cath\n",
    "\n",
    "from Bio import pairwise2\n",
    "from Bio.pairwise2 import format_alignment\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "\n",
    "import requests\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "import shutil\n",
    "\n",
    "from scipy.stats import ttest_ind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sword2(code, version, verb=False):\n",
    "    file = f\"../data/sword2/SWORD2/results/{version}/{code}/{code}_A/sword.txt\"\n",
    "    with open(file, \"r\") as f:\n",
    "        data = {}\n",
    "        lines = f.readlines()\n",
    "        option = 0\n",
    "        for i, line in enumerate(lines):\n",
    "            lines[i] = \"\".join([c for c in line if c not in [\"\\n\",'']])\n",
    "            if line != \"\\n\":\n",
    "                if not line.startswith((\"PDB:\", \"#D\", \"A\")):\n",
    "                    res = lines[i].split(\"|\")\n",
    "                    boundaries = res[2]\n",
    "                    domains = boundaries.strip().split(\" \")\n",
    "                    data[f\"option{option}\"] = {}\n",
    "                    for j in range(len(domains)):\n",
    "                        data[f\"option{option}\"][str(j+1)] = domains[j]\n",
    "                    option += 1\n",
    "    verb and pprint(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cath = get_cath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/sword2/SWORD2/misc/mappings_compact.json') as json_file:\n",
    "    pdb_uniprot_mappings = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pdb_uniprot_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdb_uniprot_mappings_reverse = {}\n",
    "\n",
    "\n",
    "# for k, v in pdb_uniprot_mappings.items():\n",
    "# \tpdb_uniprot_mappings_reverse[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # write the reverse to a file for reproducibility\n",
    "# with open('../data/sword2/SWORD2/misc/reverse_mappings_compact.json', \"w\") as json_file:\n",
    "# \tjson.dump(pdb_uniprot_mappings_reverse, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the reverse mapping\n",
    "with open('../data/sword2/SWORD2/misc/reverse_mappings_compact.json') as json_file:\n",
    "    pdb_uniprot_mappings_reverse = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "After creating a dictionary which removes the many-to-many mapping we get this many mappings:\n",
    "\"\"\"\n",
    "len(pdb_uniprot_mappings)\n",
    "len(pdb_uniprot_mappings_reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/alpha/uniprot/uniprot_alpha.json') as json_file:\n",
    "    alpha_uniprot = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alphafold_uniprots = []\n",
    "# not_alphafold_uniprots = []\n",
    "\n",
    "# sword_usable_ids = []\n",
    "# for id in alphafold_uniprots:\n",
    "#     if id in pdb_uniprot_mappings.values():\n",
    "#         sword_usable_ids.append(id)\n",
    "\n",
    "# print(\"Usable IDs that have an AlphaFold prediction:\", len(sword_usable_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sword_usable_ids = []\n",
    "\n",
    "res = alpha_uniprot['results']\n",
    "cross_ref = res[0]['uniProtKBCrossReferences']\n",
    "[x['database'] for x in cross_ref]\n",
    "\n",
    "for elt in res:\n",
    "    cross_ref = elt['uniProtKBCrossReferences']\n",
    "    dbs = [db['database'] for db in cross_ref]\n",
    "    id = elt['primaryAccession']\n",
    "      \n",
    "    if 'AlphaFoldDB' in dbs:\n",
    "        if id in pdb_uniprot_mappings_reverse.keys():\n",
    "            sword_usable_ids.append(id)\n",
    "\n",
    "\n",
    "print(\"Usable IDs that have an AlphaFold prediction:\", len(sword_usable_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(res)\n",
    "# random.choice(alphafold_uniprots)\n",
    "# random.choice(not_alphafold_uniprots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the pdb to uniprot dict because the file downloaded was 1.1gb\n",
    "# compact_mappings = {}\n",
    "\n",
    "# for elt in data['results']:\n",
    "#     pdb = elt['from']\n",
    "#     uniprot = elt['to']['primaryAccession']\n",
    "#     compact_mappings[pdb] = uniprot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/sword2/SWORD2/mappings_compact.json', 'w') as fp:\n",
    "#     json.dump(compact_mappings, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Check which IDs from the generated mappings have an AlphaFold Prediction using alphafold_uniprots\n",
    "\"\"\"\n",
    "# sword_usable_ids = []\n",
    "# for id in alphafold_uniprots:\n",
    "#     if id in pdb_uniprot_mappings.values():\n",
    "#         sword_usable_ids.append(id)\n",
    "\n",
    "print(\"Usable IDs that have an AlphaFold prediction:\", len(sword_usable_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_sword_usable_ids_before = len(sword_usable_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, v in cath.items():\n",
    "# \tif \"a\" in list(v.keys()):\n",
    "# \t\tprint(k, v)\n",
    "# \t\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pdb_uniprot_mappings_reverse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Some PDB's (from RCSB) do not have an A chain\"\"\"\n",
    "counter = 0\n",
    "for id in sword_usable_ids:\n",
    "\tpdb = pdb_uniprot_mappings_reverse[id]\n",
    "\tchains = list(cath[pdb].keys())\n",
    "\tif \"A\" not in chains:\n",
    "\t\tcounter += 1\n",
    "\t\tsword_usable_ids.remove(id)\n",
    "\t\tdel pdb_uniprot_mappings_reverse[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len_sword_usable_ids_before)\n",
    "print(counter)\n",
    "print(len(sword_usable_ids))\n",
    "print(len(pdb_uniprot_mappings_reverse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(counter)\n",
    "assert counter == len_sword_usable_ids_before - len(sword_usable_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the above to a file\n",
    "with open(\"../data/sword2/SWORD2/misc/alphafold_dataset_overlap.txt\", \"w\") as f:\n",
    "    comma_sep_ids = [x + '\\n' for x in sword_usable_ids[:-1]]\n",
    "    comma_sep_ids.append(sword_usable_ids[-1])\n",
    "    f.writelines(comma_sep_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_af_model(id):\n",
    "    \"\"\"\n",
    "    Download the Alphafold2 model corresponding to the Uniprot Id given by user\n",
    "    https://alphafold.ebi.ac.uk/\n",
    "\n",
    "    Returns:\n",
    "        - File path (string): Path of the downloaded PDB file\n",
    "        or\n",
    "        False if wrong id\n",
    "        \"DOWNLOAD ERROR\" if could not download\n",
    "    \"\"\"\n",
    "    name = f\"AF-{id}-F1-model_v3\"\n",
    "    url = f\"https://alphafold.ebi.ac.uk/files/{name}.pdb\"\n",
    "    try:\n",
    "        response = requests_retry_session().get(url)\n",
    "    except Exception as x:\n",
    "        return (False, x)\n",
    "    with open(f\"../data/sword2/SWORD2/misc/af_pdbs/{name}.pdb\", \"w\") as f:\n",
    "        f.write(response.text)\n",
    "    return (True, f\"../data/sword2/SWORD2/misc/af_pdbs/{name}.pdb\")\n",
    "\n",
    "def requests_retry_session(retries=3,\n",
    "                           backoff_factor=0.3,\n",
    "                           status_forcelist=(500, 502, 504),\n",
    "                           session=None):\n",
    "    session = session or requests.Session()\n",
    "    retry = Retry(\n",
    "        total=retries,\n",
    "        read=retries,\n",
    "        connect=retries,\n",
    "        backoff_factor=backoff_factor,\n",
    "        status_forcelist=status_forcelist,\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download all the usable ones\n",
    "\n",
    "# for id in sword_usable_ids:\n",
    "# \tdownload_af_model(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a very small file to test the pipeline that will run on the remote machine\n",
    "# with open(\"../data/sword2/SWORD2/misc/TEST_alphafold_dataset_overlap.txt\", \"w\") as f:\n",
    "#     comma_sep_ids = [x + '\\n' for x in sword_usable_ids[:3]]\n",
    "#     comma_sep_ids.append(sword_usable_ids[3])\n",
    "#     f.writelines(comma_sep_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_sim(seq1, seq2, match_score = 1, mismatch_score = -1, gap_penalty = -2):\n",
    "\talignments = pairwise2.align.globalxx(seq1, seq2)\n",
    "\n",
    "\t# Print the alignment(s)\n",
    "\t# for alignment in alignments:\n",
    "\t\t# print(format_alignment(*alignment))\n",
    "\tscore = alignments[0].score\n",
    "\tnorm_score = score / max(len(seq1), len(seq2))\n",
    "\treturn norm_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "perf_score = []\n",
    "missmatch = []\n",
    "for id in sword_usable_ids:\n",
    "\taf_pdb_file_path = f\"../data/sword2/SWORD2/misc/af_pdbs/AF-{id}-F1-model_v3.pdb\"\n",
    "\taf_chains = {record.id: record.seq for record in SeqIO.parse(af_pdb_file_path, 'pdb-seqres')}\n",
    "\ta_chain_uniprot_seq = af_chains['XXXX:A']\n",
    "\n",
    "\tpdb = pdb_uniprot_mappings_reverse[id]\n",
    "\tpdb_file_path = f\"../data/pdb/bulk/balanced/backup/data/{pdb}.pdb\"\n",
    "\tpdb_chains = {record.id: record.seq for record in SeqIO.parse(pdb_file_path, 'pdb-seqres')}\n",
    "\t\n",
    "\tfor key in pdb_chains.keys():\n",
    "\t\tif key[-1] == 'A':\n",
    "\t\t\ta_chain_pdb_seq = pdb_chains[key]\n",
    "\t\t\tbreak\n",
    "\n",
    "\tif len(a_chain_pdb_seq) == len(a_chain_uniprot_seq):\n",
    "\t\tcounter += 1\n",
    "\t\t\n",
    "\t\t# print(a_chain_uniprot_seq)\n",
    "\t\t# print(a_chain_pdb_seq)\n",
    "\t\tscore = sequence_sim(a_chain_pdb_seq, a_chain_uniprot_seq)\n",
    "\t\tif int(score) == 1:\n",
    "\t\t\tperf_score.append(id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(perf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in perf_score:\n",
    "\t# pdb_path = f'../data/sword2/SWORD2/results/pdb/{pdb}.pdb'\n",
    "\n",
    "\taf_pdb_file_path = f\"../data/sword2/SWORD2/misc/af_pdbs/AF-{id}-F1-model_v3.pdb\"\n",
    "\taf_chains = {record.id: record.seq for record in SeqIO.parse(af_pdb_file_path, 'pdb-seqres')}\n",
    "\ta_chain_uniprot_seq = af_chains['XXXX:A']\n",
    "\n",
    "\tpdb = pdb_uniprot_mappings_reverse[id]\n",
    "\tpdb_file_path = f\"../data/pdb/bulk/balanced/backup/data/{pdb}.pdb\"\n",
    "\tpdb_chains = {record.id: record.seq for record in SeqIO.parse(pdb_file_path, 'pdb-seqres')}\n",
    "\n",
    "\tfor key in pdb_chains.keys():\n",
    "\t\tif key[-1] == 'A':\n",
    "\t\t\ta_chain_pdb_seq = pdb_chains[key]\n",
    "\t\t\tbreak\n",
    "\n",
    "\tif len(a_chain_pdb_seq) != len(a_chain_uniprot_seq):\n",
    "\t\tprint(a_chain_pdb_seq)\n",
    "\t\tprint(a_chain_uniprot_seq)\n",
    "\t\tprint(abs(len(a_chain_pdb_seq) - len(a_chain_uniprot_seq)))\n",
    "\t\traise ValueError(\"Different sequence lengths is not expected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse estimation\n",
    "minutes = []\n",
    "with open(\"../data/sword2/SWORD2/misc/total_time_estimate.txt\") as f:\n",
    "\tlines = f.readlines()\n",
    "\tfor i in range(0, len(lines), 3):\n",
    "\t\t_, mins, id = lines[i], lines[i+1], lines[i+2]\n",
    "\t\tmins = mins.split('    ')\n",
    "\t\tmins = int(mins[1].strip())\n",
    "\t\tid = id.split('    ')\n",
    "\t\tid = id[1].strip()\n",
    "\t\tif id in perf_score:\n",
    "\t\t\t# print(mins, id)\n",
    "\t\t\tminutes.append((mins, id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2023)\n",
    "\n",
    "# only_mins = []\n",
    "# for (min, id) in minutes:\n",
    "# \tonly_mins.append(min)\n",
    "\n",
    "filtered = []\n",
    "for mins, id in minutes:\n",
    "\tif mins <= 10:\n",
    "\t\tfiltered.append((mins, id))\n",
    "\n",
    "# random_sample = random.sample(filtered, 500)\n",
    "\n",
    "# random_sample_only_mins = []\n",
    "# for (min, id) in random_sample:\n",
    "# \trandom_sample_only_mins.append(min)\n",
    "\n",
    "# random_sample_total_minutes = np.sum(random_sample_only_mins)\n",
    "# random_sample_total_minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdb_uniprot_mappings_reverse['P43235']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for i, (_, id) in enumerate(filtered):\n",
    "\tpdb = pdb_uniprot_mappings_reverse[id]\n",
    "\tchains = list(cath[pdb].keys())\n",
    "\tif \"A\" not in chains:\n",
    "\t\tdel filtered[i]\n",
    "\t\tcounter += 1\n",
    "\t\tprint(id)\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many are multi-domain\n",
    "single = 0\n",
    "multi = 0\n",
    "multis = []\n",
    "for (_, id) in filtered:\n",
    "\tpdb = pdb_uniprot_mappings_reverse[id]\n",
    "\tnum = len(cath[pdb]['A'])\n",
    "\tif num > 1:\n",
    "\t\tmulti += 1\n",
    "\t\tmultis.append(id)\n",
    "\telse:\n",
    "\t\tsingle += 1\n",
    "\n",
    "filtered = multis[:]\n",
    "\n",
    "print(f\"Single: {single}  --  Multi: {multi}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the IDs and PDBs to a text file for bulk\n",
    "\n",
    "with open(\"../data/sword2/SWORD2/misc/filtered_uniprots.txt\", \"w\") as ids_f:\n",
    "\twith open(\"../data/sword2/SWORD2/misc/filtered_pdbs.txt\", \"w\") as pdbs_f:\n",
    "\t\tfor id in filtered:\n",
    "\t\t\tpdb = pdb_uniprot_mappings_reverse[id]\n",
    "\t\t\tids_f.write(id + '\\n')\n",
    "\t\t\tpdbs_f.write(pdb + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set\n",
    "with open(\"../data/sword2/SWORD2/misc/TEST_filtered_uniprots.txt\", \"w\") as ids_f:\n",
    "\twith open(\"../data/sword2/SWORD2/misc/TEST_filtered_pdbs.txt\", \"w\") as pdbs_f:\n",
    "\t\tfor id in filtered[:3]:\n",
    "\t\t\tpdb = pdb_uniprot_mappings_reverse[id]\n",
    "\t\t\tids_f.write(id + '\\n')\n",
    "\t\t\tpdbs_f.write(pdb + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/sword2/SWORD2/misc/filtered_uniprots.txt\", \"r\") as f:\n",
    "\tfor line in f.readlines():\n",
    "\t\tid = line.strip()\n",
    "\t\tpdb = pdb_uniprot_mappings_reverse[id]\n",
    "\t\tpdb_path = f'../data/sword2/SWORD2/results/pdb/{pdb}.pdb'\n",
    "\n",
    "\t\taf_pdb_file_path = f\"../data/sword2/SWORD2/misc/af_pdbs/AF-{id}-F1-model_v3.pdb\"\n",
    "\t\taf_chains = {record.id: record.seq for record in SeqIO.parse(af_pdb_file_path, 'pdb-seqres')}\n",
    "\t\ta_chain_uniprot_seq = af_chains['XXXX:A']\n",
    "\n",
    "\t\tpdb_file_path = f\"../data/pdb/bulk/balanced/backup/data/{pdb}.pdb\"\n",
    "\t\tpdb_chains = {record.id: record.seq for record in SeqIO.parse(pdb_file_path, 'pdb-seqres')}\n",
    "\n",
    "\t\tfor key in pdb_chains.keys():\n",
    "\t\t\tif key[-1] == 'A':\n",
    "\t\t\t\ta_chain_pdb_seq = pdb_chains[key]\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\tif len(a_chain_pdb_seq) != len(a_chain_uniprot_seq):\n",
    "\t\t\tprint(a_chain_pdb_seq)\n",
    "\t\t\tprint(a_chain_uniprot_seq)\n",
    "\t\t\tprint(abs(len(a_chain_pdb_seq) - len(a_chain_uniprot_seq)))\n",
    "\t\t\traise ValueError(\"Different sequence lengths is not expected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the pdb files in a seperate directory\n",
    "\n",
    "with open(\"../data/sword2/SWORD2/misc/filtered_uniprots.txt\", \"r\") as f:\n",
    "\tfor line in f.readlines():\n",
    "\t\tid = line.strip()\n",
    "\t\tpdb = pdb_uniprot_mappings_reverse[id]\n",
    "\t\tpdb_path = f'../data/pdb/bulk/balanced/backup/data/{pdb}.pdb'\n",
    "\n",
    "\t\tshutil.copy(pdb_path, '../data/sword2/SWORD2/misc/pdb_files/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundaries2(len_seq, domain, discontinuity_delimiter):\n",
    "\t\"\"\"\n",
    "\t\tDefines a boundary as the beginning of a domain ONLY in multi-domain proteins\n",
    "\t\"\"\"\n",
    "\tfirst_start = np.inf\n",
    "\tbounds = np.zeros((len_seq), dtype=np.int8)\n",
    "\tfor k, v in domain.items():\n",
    "\t\tboundary_positions = v.split(discontinuity_delimiter)\n",
    "\t\tfor b in boundary_positions:\n",
    "\t\t\tstart, end = [int(i) for i in b.split('-')]\n",
    "\t\t\tif start < first_start:\n",
    "\t\t\t\tfirst_start = start\n",
    "\t\t\tbounds[start-1] = 1\n",
    "\tbounds[first_start-1] = 0            \n",
    "\treturn np.array(bounds, dtype=np.bool_)\n",
    "\n",
    "\n",
    "def dbd_score(y_pred, y_true, margin=20):\n",
    "    scores = []\n",
    "    for i in range(len(y_pred)):\n",
    "        window = y_true[max(0, i-margin):min(len(y_true), i+margin+1)]\n",
    "        indices_window = list(range(max(0, i-margin), min(len(y_true), i+margin+1)))\n",
    "        if y_pred[i] == 1.0:\n",
    "            if 1.0 in window:\n",
    "                # if it's within the window, calculate the score\n",
    "                pos = np.where(window == 1.0)[0][0]\n",
    "                j = indices_window[pos]\n",
    "                diff = abs(i - j)\n",
    "                k = 0 if diff == 0 else 1\n",
    "                score = ((margin - diff) + k) / margin\n",
    "            else:\n",
    "                # false positive\n",
    "                score = 0\n",
    "            scores.append(score)\n",
    "\n",
    "    number_of_true_boundaries = np.sum(y_true)\n",
    "    number_of_pred_boundaries = np.sum(y_pred)\n",
    "    max_len = max(number_of_true_boundaries,number_of_pred_boundaries)\n",
    "    if max_len == 0:\n",
    "        return 1.0\n",
    "\n",
    "    return np.sum(scores) / max_len\n",
    "\n",
    "\n",
    "def metrics(y_pred, y_true, margin=20):\n",
    "    true_positive = 0\n",
    "    true_negative = 0\n",
    "    false_negative = 0\n",
    "    false_positive = 0\n",
    "\n",
    "    for i in range(len(y_pred)):\n",
    "        window = y_true[max(0, i-margin):min(len(y_true), i+margin+1)]\n",
    "        if y_pred[i] == 1.0:\n",
    "            if 1.0 in window:\n",
    "                true_positive += 1\n",
    "            else:\n",
    "                false_positive += 1\n",
    "\n",
    "\n",
    "        elif y_pred[i] == 0.0:\n",
    "            if  y_true[i] == 1.0:\n",
    "                false_negative += 1\n",
    "            else:\n",
    "                true_negative += 1\n",
    "\n",
    "    try:\n",
    "        accuracy = (true_negative + true_positive) / (true_negative + true_positive + false_negative + false_positive)\n",
    "    except ZeroDivisionError:\n",
    "        accuracy = 0\n",
    "\n",
    "    try:\n",
    "        precision = true_positive / (true_positive + false_positive)\n",
    "    except ZeroDivisionError:\n",
    "        precision = 0\n",
    "\n",
    "    try:\n",
    "        recall = true_positive / (true_positive + false_negative)\n",
    "    except ZeroDivisionError:\n",
    "        recall = 0\n",
    "\n",
    "    try:\n",
    "        f1 = (2 * precision * recall) / (precision + recall)\n",
    "    except ZeroDivisionError:\n",
    "        f1 = 0\n",
    "\n",
    "    try:\n",
    "        mcc = ((true_positive * true_negative) - (false_positive * false_negative)) / ((true_positive + false_positive) * (true_positive + false_negative) * (true_negative + false_positive) * (true_negative + false_negative))**0.5\n",
    "    except ZeroDivisionError:\n",
    "        mcc = 0\n",
    "\n",
    "    dbd = dbd_score(y_pred, y_true, margin)\n",
    "\n",
    "    return (accuracy, precision, recall, f1, mcc, dbd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/sword2/SWORD2/results/af'\n",
    "\n",
    "uniprots = os.listdir(path)\n",
    "# print(uniprots)\n",
    "# print()\n",
    "\n",
    "pdb_mcc = []\n",
    "af_mcc = []\n",
    "\n",
    "for i, id in enumerate(uniprots):\n",
    "\n",
    "    if id != 'A0NLY7':\n",
    "        continue\n",
    "\n",
    "    pdb = pdb_uniprot_mappings_reverse[id]\n",
    "    pdb_path = f'../data/sword2/SWORD2/results/pdb/{pdb}.pdb'\n",
    "\n",
    "    af_pdb_file_path = f\"../data/sword2/SWORD2/misc/af_pdbs/AF-{id}-F1-model_v3.pdb\"\n",
    "    af_chains = {record.id: record.seq for record in SeqIO.parse(af_pdb_file_path, 'pdb-seqres')}\n",
    "    a_chain_uniprot_seq = af_chains['XXXX:A']\n",
    "\n",
    "    pdb_file_path = f\"../data/pdb/bulk/balanced/backup/data/{pdb}.pdb\"\n",
    "    pdb_chains = {record.id: record.seq for record in SeqIO.parse(pdb_file_path, 'pdb-seqres')}\n",
    "\n",
    "    for key in pdb_chains.keys():\n",
    "        if key[-1] == 'A':\n",
    "            a_chain_pdb_seq = pdb_chains[key]\n",
    "            break\n",
    "\n",
    "    if len(a_chain_pdb_seq) != len(a_chain_uniprot_seq):\n",
    "        print(a_chain_pdb_seq)\n",
    "        print(a_chain_uniprot_seq)\n",
    "        print(abs(len(a_chain_pdb_seq) - len(a_chain_uniprot_seq)))\n",
    "        raise ValueError(\"Different sequence lengths is not expected\")\n",
    "    else:\n",
    "        baseline = cath[pdb]['A']\n",
    "        print(\"True domain boundaries from CATH:\", baseline)\n",
    "        # print(\"Length:\", len(a_chain_pdb_seq))\n",
    "        # print(id)\n",
    "        af_sword_results = get_sword2(id, 'af', verb=False)\n",
    "        # print(pdb)\n",
    "        try:\n",
    "            pdb_sword_results = get_sword2(pdb, 'pdb', verb=False)\n",
    "        except FileNotFoundError:\n",
    "            print(\"File not found\")\n",
    "            print(id, pdb)\n",
    "            continue\n",
    "\n",
    "\n",
    "        margin = 8\n",
    "        baseline_boundaries = boundaries2(len(a_chain_pdb_seq), baseline, ',').astype(int)\n",
    "        pdb_mccs = []\n",
    "        af_mccs = []\n",
    "        pdb_dbds = []\n",
    "        af_dbds = []\n",
    "\n",
    "        print(id, pdb)\n",
    "\n",
    "        print(\"pdb\")\n",
    "        for option, domain in pdb_sword_results.items():\n",
    "            pdb_sword_boundaries = boundaries2(len(a_chain_pdb_seq), domain, ';').astype(int)\n",
    "            pdb_sword_metrics = metrics(pdb_sword_boundaries, baseline_boundaries, margin)\n",
    "            pdb_sword_mcc = pdb_sword_metrics[-2]\n",
    "            pdb_sword_dbd = pdb_sword_metrics[-1]\n",
    "            pdb_mccs.append(pdb_sword_mcc)\n",
    "            pdb_dbds.append(pdb_sword_dbd)\n",
    "            print(option)\n",
    "            print(domain)\n",
    "            print(pdb_sword_mcc)\n",
    "            print()\n",
    "\n",
    "        print(\"af\")\n",
    "        for option, domain in af_sword_results.items():\n",
    "            af_sword_boundaries = boundaries2(len(a_chain_pdb_seq), domain, ';').astype(int)\n",
    "            af_sword_metrics = metrics(af_sword_boundaries, baseline_boundaries, margin)\n",
    "            af_sword_mcc = af_sword_metrics[-2]\n",
    "            af_sword_dbd = af_sword_metrics[-1]\n",
    "            af_mccs.append(af_sword_mcc)\n",
    "            af_dbds.append(af_sword_dbd)\n",
    "            print(option)\n",
    "            print(domain)\n",
    "            print(af_sword_boundaries)\n",
    "            print(af_sword_mcc)\n",
    "            print()\n",
    "\n",
    "        best_pdb_i = np.argmax(pdb_mccs)\n",
    "        best_af_i = np.argmax(af_mccs)\n",
    "\n",
    "        pdb_mcc.append(pdb_mccs[best_pdb_i])\n",
    "        af_mcc.append(af_mccs[best_af_i])\n",
    "\n",
    "    if (i + 1) % 50 == 0:\n",
    "        print(f\"[{i}/{len(uniprots)}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.39084160550465 0.0008410867748462028\n"
     ]
    }
   ],
   "source": [
    "t_stat, p_val = ttest_ind(pdb_mcc[:100], af_mcc[:100])\n",
    "\n",
    "print(t_stat, float(p_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43234073554287933\n",
      "0.5675947560551442\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(pdb_mcc[:100]))\n",
    "print(np.mean(af_mcc[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "\n",
    "# calculate the mean MCC values\n",
    "mean_mcc_a = np.mean(pdb_mccs)\n",
    "mean_mcc_b = np.mean(af_mccs)\n",
    "\n",
    "# perform a two-sample t-test\n",
    "t_stat, p_value = ttest_ind(pdb_mccs, af_mccs)\n",
    "\n",
    "print(\"Mean MCC for model A: \", mean_mcc_a)\n",
    "print(\"Mean MCC for model B: \", mean_mcc_b)\n",
    "print(\"t-statistic: \", t_stat)\n",
    "print(\"p-value: \", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b6993604730f8cf29f5900b73e8b88206f8a6983047fdc957f382b3e5d49baa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
