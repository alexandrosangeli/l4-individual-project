{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.nn import Module\n",
    "from torch.nn import Conv1d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import LogSoftmax\n",
    "from torch import flatten\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from metrics.helper import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_seq(seq, logits):\n",
    "    # parse a sequence (which will be the output from the model)\n",
    "    # for every series of consecutive ones, leave only the median as one - the rest turn to 0\n",
    "    # seq = [1,1,0,0,0,0,0,1,1,1,0,0,0,0,0,1,1,1,0,1,1]\n",
    "    new_seq = np.zeros(len(seq))\n",
    "    consecutive_ones_indices = []\n",
    "    medians = []\n",
    "\n",
    "    # marks if the first consecutive zeros that are less than the typical size is the first (meaning is the beginning of the first domain)\n",
    "    for i in range(len(seq)):\n",
    "        if seq[i] == 0:\n",
    "            if len(consecutive_ones_indices) > 0:\n",
    "                h = [logits[elt] for elt in consecutive_ones_indices]\n",
    "                point = consecutive_ones_indices[np.argmax(h)]\n",
    "                medians.append(point)\n",
    "            consecutive_ones_indices = []\n",
    "\n",
    "        if seq[i] == 1:\n",
    "            consecutive_ones_indices.append(i)\n",
    "\n",
    "    if len(consecutive_ones_indices) > 0:\n",
    "        h = [logits[elt] for elt in consecutive_ones_indices]\n",
    "        point = consecutive_ones_indices[np.argmax(h)]\n",
    "        medians.append(point)\n",
    "\n",
    "    for elt in medians:\n",
    "        new_seq[elt] = 1\n",
    "\n",
    "    return new_seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(Module):\n",
    "    def __init__(self, numChannels=20):\n",
    "        # call the parent constructor\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = Conv1d(in_channels=numChannels, out_channels=15, kernel_size=15, padding=7)\n",
    "        self.sig1 = nn.Sigmoid()\n",
    "        self.conv2 = Conv1d(in_channels=15, out_channels=10, kernel_size=15, padding=7)\n",
    "        self.sig2 = nn.Sigmoid()\n",
    "        self.conv3 = Conv1d(in_channels=10, out_channels=5, kernel_size=15, padding=7)\n",
    "        self.sig3 = nn.Sigmoid()\n",
    "        self.conv4 = Conv1d(in_channels=5, out_channels=2, kernel_size=15, padding=7)\n",
    "        self.sig4 = nn.Sigmoid()\n",
    "        self.conv5 = Conv1d(in_channels=2, out_channels=1, kernel_size=15, padding=7)\n",
    "        self.sig5 = nn.Sigmoid()\n",
    "        # self.logSoftmax = LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.sig1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.sig2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.sig3(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.sig4(x)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.sig5(x)\n",
    "        \n",
    "        # output = self.logSoftmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, transform):\n",
    "        self.data = pd.read_pickle('../../data/cnn/one_hot/data.csv')\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # x = input[index].T # channels should be first\n",
    "        # y = output[index].reshape((1, -1)) # make the data match the shape of X after passing through all layers\n",
    "        x = self.data['in'].iloc[index]\n",
    "        # if index == 1:\n",
    "        #     print(x.shape)\n",
    "        # x = x.T\n",
    "        y = self.data['out'].iloc[index]\n",
    "        y = y.reshape((1,-1))\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)[0]\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SequenceDataset(transforms.ToTensor())\n",
    "length = len(pd.read_pickle('../../data/cnn/one_hot/data.csv'))\n",
    "train_len = (length * 9) // 10\n",
    "test_len = length - train_len\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [train_len, test_len])\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=1, shuffle=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = CNN().double()\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.669\n",
      "[1,  4000] loss: 0.666\n",
      "[1,  6000] loss: 0.660\n",
      "[1,  8000] loss: 0.658\n",
      "[1, 10000] loss: 0.654\n",
      "[1, 12000] loss: 0.652\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, target) in enumerate(train_loader):\n",
    "\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        target = target.reshape(-1)\n",
    "        outputs = outputs.reshape(-1)\n",
    "        # print(target)\n",
    "        # print()\n",
    "        # print(outputs)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            \n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test\n",
    "def test(model, threshhold=0.5):\n",
    "    with torch.no_grad():\n",
    "        n_samples = len(test_loader)\n",
    "        accuracy = 0\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "        f1 = 0\n",
    "        for input, target in test_loader:\n",
    "            outputs = model(input)\n",
    "            outputs = outputs.reshape(-1).to(device)\n",
    "            # outputs = torch.round(outputs)\n",
    "            target = target.reshape(-1).to(device)\n",
    "            outputs = (outputs > threshhold).float()\n",
    "            # print(outputs)\n",
    "            # print()\n",
    "            # print(target)\n",
    "            # break\n",
    "            accuracy_, precision_, recall_, f1_ = metrics(outputs, target)\n",
    "            accuracy += accuracy_\n",
    "            precision += precision_\n",
    "            f1 += f1_\n",
    "            recall += recall_\n",
    "\n",
    "        accuracy = accuracy / n_samples\n",
    "        precision = precision / n_samples\n",
    "        recall = recall / n_samples\n",
    "        f1 = f1 / n_samples\n",
    "\n",
    "        print(f'Accuracy: {accuracy}')\n",
    "        print(f'Precision: {precision}')\n",
    "        print(f'Recall: {recall}')\n",
    "        print(f'F1: {f1}')\n",
    "\n",
    "    return (accuracy, precision, recall, f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshhold: 0.3\n",
      "Accuracy: 0.38765762530392006\n",
      "Precision: 0.38765762530392006\n",
      "Recall: 1.0\n",
      "F1: 0.5434704150216114\n",
      "\n",
      "Threshhold: 0.4\n",
      "Accuracy: 0.6771696790656383\n",
      "Precision: 0.8859814331422823\n",
      "Recall: 0.20043380234170646\n",
      "F1: 0.30214252537713693\n",
      "\n",
      "Threshhold: 0.5\n",
      "Accuracy: 0.6320278421061355\n",
      "Precision: 0.9257893838538999\n",
      "Recall: 0.05734024226333336\n",
      "F1: 0.10469450157570968\n",
      "\n",
      "Threshhold: 0.6\n",
      "Accuracy: 0.6123423746960799\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1: 0.0\n",
      "\n",
      "Threshhold: 0.7\n",
      "Accuracy: 0.6123423746960798\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshholds = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "for t in threshholds:\n",
    "    print(f\"Threshhold: {t}\")\n",
    "    test(model, t)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b6993604730f8cf29f5900b73e8b88206f8a6983047fdc957f382b3e5d49baa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
