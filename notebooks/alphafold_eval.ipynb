{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from helpers.helper import get_cath\n",
    "\n",
    "from Bio import pairwise2\n",
    "from Bio.pairwise2 import format_alignment\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "\n",
    "import requests\n",
    "import shutil\n",
    "from Bio import pairwise2\n",
    "from Bio.pairwise2 import format_alignment\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "\n",
    "\n",
    "from scipy.stats import ttest_ind\n",
    "from pprint import pprint\n",
    "\n",
    "cath = get_cath()\n",
    "metric_indices_dict = {\n",
    "    'acc' : 0,\n",
    "    'pre' : 1,\n",
    "    'rec' : 2,\n",
    "    'f1' : 3,\n",
    "    'mcc' : 4,\n",
    "    'dbd' : 5\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sword2(code, chain, version, verb=False):\n",
    "    file = f\"../data/sword2/final_results/results/{version}/{code}/{code}_{chain}/sword.txt\"\n",
    "    with open(file, \"r\") as f:\n",
    "        data = {}\n",
    "        lines = f.readlines()\n",
    "        option = 0\n",
    "        for i, line in enumerate(lines):\n",
    "            lines[i] = \"\".join([c for c in line if c not in [\"\\n\",'']])\n",
    "            if line != \"\\n\":\n",
    "                if not line.startswith((\"PDB:\", \"#D\", \"A\")):\n",
    "                    res = lines[i].split(\"|\")\n",
    "                    boundaries = res[2]\n",
    "                    domains = boundaries.strip().split(\" \")\n",
    "                    data[f\"option{option}\"] = {}\n",
    "                    for j in range(len(domains)):\n",
    "                        data[f\"option{option}\"][str(j+1)] = domains[j]\n",
    "                    option += 1\n",
    "    verb and pprint(data)\n",
    "    return data\n",
    "\n",
    "\n",
    "def sequence_sim(seq1, seq2, match_score = 1, mismatch_score = -1, gap_penalty = -2):\n",
    "    alignments = pairwise2.align.globalxx(seq1, seq2)\n",
    "\n",
    "    # Print the alignment(s)\n",
    "    # for alignment in alignments:\n",
    "        # print(format_alignment(*alignment))\n",
    "    score = alignments[0].score\n",
    "    norm_score = score / max(len(seq1), len(seq2))\n",
    "    return norm_score\n",
    "\n",
    "\n",
    "\n",
    "def dbd_score(y_pred, y_true, margin=20):\n",
    "    scores = []\n",
    "    for i in range(len(y_pred)):\n",
    "        window = y_true[max(0, i-margin):min(len(y_true), i+margin+1)]\n",
    "        indices_window = list(range(max(0, i-margin), min(len(y_true), i+margin+1)))\n",
    "        if y_pred[i] == 1.0:\n",
    "            if 1.0 in window:\n",
    "                # if it's within the window, calculate the score\n",
    "                pos = np.where(window == 1.0)[0][0]\n",
    "                j = indices_window[pos]\n",
    "                diff = abs(i - j)\n",
    "                k = 0 if diff == 0 else 1\n",
    "                score = ((margin - diff) + k) / margin\n",
    "            else:\n",
    "                # false positive\n",
    "                score = 0\n",
    "            scores.append(score)\n",
    "\n",
    "    number_of_true_boundaries = np.sum(y_true)\n",
    "    number_of_pred_boundaries = np.sum(y_pred)\n",
    "    max_len = max(number_of_true_boundaries,number_of_pred_boundaries)\n",
    "    if max_len == 0:\n",
    "        return 1.0\n",
    "\n",
    "    return np.sum(scores) / max_len\n",
    "\n",
    "\n",
    "def observations(y_pred, y_true, margin):\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "\n",
    "    dbd = dbd_score(y_pred, y_true, margin)\n",
    "    for i in range(len(y_pred)):\n",
    "        window = y_true[max(0, i-margin):min(len(y_true), i+margin+1)]\n",
    "        indices_window = list(range(max(0, i-margin), min(len(y_true), i+margin+1)))\n",
    "        if y_pred[i] == 1.0:\n",
    "            if 1.0 in window:\n",
    "                pos = np.where(window == 1.0)[0][0]\n",
    "                j = indices_window[pos]\n",
    "                y_true[j] = 0.0\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] == 0.0:\n",
    "            if  y_true[i] == 1.0:\n",
    "                fn += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "\n",
    "    return (tp, tn, fp, fn)\n",
    "\n",
    "\n",
    "def metrics(y_pred, y_true, margin=20):\n",
    "    tp, tn, fp, fn = observations(y_pred, y_true, margin)\n",
    "\n",
    "    accuracy = (tn + tp) / (tn + tp + fn + fp) if (tn + tp + fn + fp) else 0\n",
    "    precision = tp / (tp + fp) if (tp + fp) else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) else 0\n",
    "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "\n",
    "    mcc_num = (tp * tn) - (fp * fn)\n",
    "    mcc_den = np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "    mcc = mcc_num / mcc_den if mcc_den else 0\n",
    "\n",
    "    dbd = dbd_score(y_pred, y_true, margin)\n",
    "\n",
    "    return (accuracy, precision, recall, f1, mcc, dbd)\n",
    "\n",
    "\n",
    "def boundaries(len_seq, domain, discontinuity_delimiter):\n",
    "    \"\"\"\n",
    "        Defines a boundary as the beginning of a domain ONLY in multi-domain proteins\n",
    "    \"\"\"\n",
    "    first_start = np.inf\n",
    "    bounds = np.zeros((len_seq), dtype=np.int8)\n",
    "    for k, v in domain.items():\n",
    "        boundary_positions = v.split(discontinuity_delimiter)\n",
    "        for b in boundary_positions:\n",
    "            start, end = [int(i) for i in b.split('-')]\n",
    "            if start < first_start:\n",
    "                first_start = start\n",
    "            bounds[start-1] = 1\n",
    "    bounds[first_start-1] = 0            \n",
    "    return np.array(bounds, dtype=np.bool_)\n",
    "\n",
    "\n",
    "def get_af_chain(code, chain):\n",
    "    file_path = f\"../data/sword2/SWORD2/misc/new_iid/af_pdbs/AF-{code}-F1-model_v3.pdb\"\n",
    "    chains = {record.id: record.seq for record in SeqIO.parse(file_path, 'pdb-seqres')}\n",
    "    seq = chains.get(f'XXXX:{chain}')\n",
    "    return seq\n",
    "\n",
    "\n",
    "def get_pdb_chain(code, chain):\n",
    "    pdb_file_path = f\"../data/pdb/new_iid/{code}.pdb\"\n",
    "    pdb_chains = {record.id: record.seq for record in SeqIO.parse(pdb_file_path, 'pdb-seqres')}\n",
    "\n",
    "    for key in pdb_chains.keys():\n",
    "        if key[-1] == chain:\n",
    "            a_chain_pdb_seq = pdb_chains[key]\n",
    "            return a_chain_pdb_seq\n",
    "                \n",
    "        \n",
    "# def get_num_of_domains(code)\n",
    "\n",
    "\n",
    "def get_best_sword_option(true_boundaries, sword_results_dict, seq_len, margin, metric_index):\n",
    "    mccs = []\n",
    "    results = []\n",
    "    for option, domain in sword_results_dict.items():\n",
    "        baseline_boundaries = boundaries(seq_len, domain, ';').astype(int)\n",
    "        metrics_results = metrics(baseline_boundaries, true_boundaries, margin)\n",
    "        mcc = metrics_results[metric_index]\n",
    "        mccs.append(mcc)\n",
    "        results.append(metrics_results)\n",
    "    return results[np.argmax(mccs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/sword2/SWORD2/misc/new_iid/pdb_to_uniprot_map.json') as json_file:\n",
    "    pdb_to_uni_map = json.load(json_file)\n",
    "    \n",
    "pdb_to_af_map = {}\n",
    "for elt in pdb_to_uni_map['results']:\n",
    "    pdb = elt['from']\n",
    "    databases = [db['database'] for db in elt['to']['uniProtKBCrossReferences']]\n",
    "    for i, db in enumerate(databases):\n",
    "        if db == 'AlphaFoldDB':\n",
    "            af_id = (elt['to']['uniProtKBCrossReferences'][i]['id'])\n",
    "            if pdb_to_af_map.get(pdb):\n",
    "                pdb_to_af_map[pdb].append(af_id)\n",
    "            else:\n",
    "                pdb_to_af_map[pdb] = [af_id]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/cath/iid/chains_to_seq_iid.json') as json_file:\n",
    "    chain_to_seq_iid = json.load(json_file)\n",
    "\n",
    "valid_pairs = []\n",
    "for chain, seq in chain_to_seq_iid.items():\n",
    "    if pdb_to_af_map.get(chain[:4]):\n",
    "        pdb_filename = f\"../data/pdb/new_iid/{chain[:4]}.pdb\"\n",
    "        chain_id = chain[-1]\n",
    "        with open(pdb_filename, \"r\") as pdb_file:\n",
    "            pdb_chains = {record.id: record.seq for record in SeqIO.parse(pdb_file, 'pdb-seqres')}\n",
    "            for key in pdb_chains.keys():\n",
    "                if key[-1] == chain[-1]:\n",
    "                    pdb_seq = pdb_chains[key]\n",
    "        af_seqs = []\n",
    "        for uniprot in pdb_to_af_map.get(chain[:4]):\n",
    "            af_seq = get_af_chain(uniprot, chain[-1])\n",
    "            if af_seq:\n",
    "                af_seqs.append((uniprot, af_seq))\n",
    "        for (uniprot, af_seq) in af_seqs:\n",
    "            if len(af_seq) == len(pdb_seq):\n",
    "                sim = sequence_sim(af_seq, pdb_seq)\n",
    "                if sim == 1.0:\n",
    "                    valid_pairs.append((chain, uniprot + f':{chain[-1]}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1a2k:A', 'P61972:A')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "508"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs' order match\n"
     ]
    }
   ],
   "source": [
    "for (pdb, af) in valid_pairs:\n",
    "    pdb_seq = get_pdb_chain(pdb[:-2], pdb[-1])\n",
    "    af_seq = get_af_chain(af[:-2], af[-1])\n",
    "    assert pdb_seq == af_seq\n",
    "print(\"Pairs' order match\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDB File 2h47:A does not exist\n",
      "PDB File P13479:A does not exist\n",
      "PDB File 2w02:A does not exist\n",
      "PDB File B5THI3:A does not exist\n",
      "PDB File 4wl9:A does not exist\n"
     ]
    }
   ],
   "source": [
    "path = '../data/sword2/final_results/results/'\n",
    "for (pdb, af) in valid_pairs:\n",
    "    try:\n",
    "        pdb_sword = get_sword2(pdb[:-2], pdb[-1], 'pdb')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"PDB File {pdb} does not exist\")\n",
    "    \n",
    "    try:\n",
    "        af_sword = get_sword2(af[:-2], af[-1], 'af')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"PDB File {af} does not exist\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2h47:A and P84888:A\n",
      "P13479:A and 2vlp:A\n",
      "2w02:A  and Q93AT8:A\n",
      "B5THI3:A and 4rej:A\n",
      "4wl9:A  and P16113:A\n"
     ]
    }
   ],
   "source": [
    "for i, (pdb, af) in enumerate(valid_pairs):\n",
    "    if pdb == \"2h47:A\":\n",
    "        print(\"2h47:A and\", af)\n",
    "\n",
    "    if pdb == \"2w02:A\":\n",
    "        print(\"2w02:A  and\", af)\n",
    "\n",
    "    if pdb == \"4wl9:A\":\n",
    "        print(\"4wl9:A  and\", af)\n",
    "        \n",
    "    if af == \"P13479:A\":\n",
    "        print(\"P13479:A and\", pdb)\n",
    "\n",
    "    if af == \"B5THI3:A\":\n",
    "        print(\"B5THI3:A and\", pdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go ahead and evaluate!\n"
     ]
    }
   ],
   "source": [
    "for i, (pdb, af) in enumerate(valid_pairs):\n",
    "    if pdb in [\"2h47:A\", \"2w02:A\", \"4wl9:A\"]:\n",
    "        del valid_pairs[i]\n",
    "        \n",
    "    if af in [\"P13479:A\", \"B5THI3:A\"]:\n",
    "        del valid_pairs[i]\n",
    "        \n",
    "for i, (pdb, af) in enumerate(valid_pairs):\n",
    "    assert pdb != \"2h47:A\" and af != \"P84888:A\"\n",
    "    assert af != \"P13479:A\" and pdb != \"2vlp:A\"\n",
    "    assert af != \"2w02:A\" and pdb != \"Q93AT8:A\"\n",
    "    assert af != \"B5THI3:A\" and pdb != \"4rej:A\"\n",
    "    assert af != \"4wl9:A\" and pdb != \"P16113:A\"\n",
    "\n",
    "print(\"Go ahead and evaluate!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "503"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(metric_of_interest):\n",
    "    \"\"\"\n",
    "    Return the mean metric after the evaluation\n",
    "    \"\"\"\n",
    "    margin = 20\n",
    "    p = []\n",
    "    a = []\n",
    "    for (pdb, af) in valid_pairs:\n",
    "        metric_index = metric_indices_dict[metric_of_interest]\n",
    "        chain_len = len(get_pdb_chain(pdb[:4], pdb[-1]))\n",
    "        baseline = cath[pdb[:4]][pdb[-1]]\n",
    "        baseline_boundaries = boundaries(chain_len, baseline, ',').astype(int)\n",
    "        if sum(baseline_boundaries) > 0:\n",
    "            pdb_sword = get_sword2(pdb[:-2], pdb[-1], 'pdb')\n",
    "            af_sword = get_sword2(af[:-2], af[-1], 'af')\n",
    "            pdb_metrics = get_best_sword_option(baseline_boundaries, pdb_sword, chain_len, margin, metric_index)\n",
    "            af_metrics = get_best_sword_option(baseline_boundaries, af_sword, chain_len, margin, metric_index)\n",
    "            a.append(af_metrics[metric_index])\n",
    "            p.append(pdb_metrics[metric_index])\n",
    "        \n",
    "    return (np.mean(p), np.mean(a))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5794446057895699, 0.19707455073244642)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate('mcc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.996145081302511, 0.9965586647401254)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate('acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
