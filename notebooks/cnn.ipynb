{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.nn import Module\n",
    "from torch.nn import Conv1d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import LogSoftmax\n",
    "from torch import flatten\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from helpers.models.helper import accuracy, accuracy20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(Module):\n",
    "    def __init__(self, numChannels=20):\n",
    "        # call the parent constructor\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = Conv1d(in_channels=numChannels, out_channels=15, kernel_size=15, padding=7)\n",
    "        self.relu1 = nn.Sigmoid()\n",
    "        self.conv2 = Conv1d(in_channels=15, out_channels=10, kernel_size=15, padding=7)\n",
    "        self.relu2 = nn.Sigmoid()\n",
    "        self.conv3 = Conv1d(in_channels=10, out_channels=5, kernel_size=15, padding=7)\n",
    "        self.relu3 = nn.Sigmoid()\n",
    "        self.conv4 = Conv1d(in_channels=5, out_channels=2, kernel_size=15, padding=7)\n",
    "        self.relu4 = nn.Sigmoid()\n",
    "        self.conv5 = Conv1d(in_channels=2, out_channels=1, kernel_size=15, padding=7)\n",
    "        self.relu5 = nn.Sigmoid()\n",
    "        # self.logSoftmax = LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.relu5(x)\n",
    "        # output = self.logSoftmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, transform):\n",
    "        self.data = pd.read_pickle('../data/cnn/data.csv')\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # x = input[index].T # channels should be first\n",
    "        # y = output[index].reshape((1, -1)) # make the data match the shape of X after passing through all layers\n",
    "        x = self.data['in'].iloc[index]\n",
    "        # if index == 1:\n",
    "        #     print(x.shape)\n",
    "        # x = x.T\n",
    "        y = self.data['out'].iloc[index]\n",
    "        y = y.reshape((1,-1))\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)[0]\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input = np.random.uniform(low=0, high=1, size=(100, 100, 20))\n",
    "# output = np.random.uniform(low=0, high=1, size=(100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SequenceDataset(transforms.ToTensor())\n",
    "length = len(pd.read_pickle('../data/cnn/data.csv'))\n",
    "train_len = (length * 9) // 10\n",
    "test_len = length - train_len\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [train_len, test_len])\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=1, shuffle=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = CNN().double()\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.308\n",
      "[1,  4000] loss: 0.309\n",
      "[1,  6000] loss: 0.297\n",
      "[1,  8000] loss: 0.292\n",
      "[2,  2000] loss: 0.301\n",
      "[2,  4000] loss: 0.294\n",
      "[2,  6000] loss: 0.295\n",
      "[2,  8000] loss: 0.290\n",
      "[3,  2000] loss: 0.285\n",
      "[3,  4000] loss: 0.294\n",
      "[3,  6000] loss: 0.297\n",
      "[3,  8000] loss: 0.294\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, target) in enumerate(train_loader):\n",
    "\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        target = target.reshape(-1)\n",
    "        outputs = outputs.reshape(-1)\n",
    "        # print(target)\n",
    "        # print()\n",
    "        # print(outputs)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5817649269079165 %\n"
     ]
    }
   ],
   "source": [
    "# # test\n",
    "with torch.no_grad():\n",
    "    n_samples = 0\n",
    "    total_acc = 0\n",
    "    for input, target in test_loader:\n",
    "        outputs = model(input)\n",
    "        outputs = outputs.reshape(-1).to(device)\n",
    "        outputs = torch.round(outputs)\n",
    "\n",
    "        target = target.reshape(-1).to(device)\n",
    "        # print(outputs)\n",
    "        # print()\n",
    "        # print(target)\n",
    "        acc = accuracy20(outputs, target)\n",
    "        total_acc += acc\n",
    "        # max returns (value ,index)\n",
    "        # _, predicted = torch.max(outputs.data, 1)\n",
    "        # n_samples += labels.size(0)\n",
    "        # n_correct += (predicted == labels).sum().item()\n",
    "    mean_acc = total_acc / len(test_loader)\n",
    "    # acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy: {mean_acc} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b6993604730f8cf29f5900b73e8b88206f8a6983047fdc957f382b3e5d49baa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
